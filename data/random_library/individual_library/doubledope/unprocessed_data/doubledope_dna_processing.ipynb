{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import re\n",
    "import regex as re\n",
    "from collections import Counter, defaultdict\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "CONST_A = 0\n",
    "CONST_C = 1\n",
    "CONST_G = 2\n",
    "CONST_T = 3\n",
    "\n",
    "CONST_NT_MAP = ['A', 'C', 'G', 'T']\n",
    "\n",
    "def reverse_complement(seq) :\n",
    "    rc_seq = ''\n",
    "    for i in range(0, len(seq)) :\n",
    "        if seq[i] == 'A' :\n",
    "            rc_seq = 'T' + rc_seq\n",
    "        elif seq[i] == 'C' :\n",
    "            rc_seq = 'G' + rc_seq\n",
    "        elif seq[i] == 'G' :\n",
    "            rc_seq = 'C' + rc_seq\n",
    "        elif seq[i] == 'T' :\n",
    "            rc_seq = 'A' + rc_seq\n",
    "    return rc_seq\n",
    "\n",
    "def distance(astring, bstring) :\n",
    "    distance = 0\n",
    "    \n",
    "    limit = len(astring)\n",
    "    diff = len(bstring) - len(astring)\n",
    "    if len(bstring) < len(astring) :\n",
    "        limit = len(bstring)\n",
    "        diff = len(astring) - len(bstring)\n",
    "    \n",
    "    for i in range(limit) :\n",
    "        if astring[i] != bstring[i] :\n",
    "            distance += 1\n",
    "    return distance + diff\n",
    "\n",
    "def increment_bp_map(seq, bp_map, magnitude=1) :\n",
    "    for i in range(0, len(seq)) :\n",
    "        if seq[i] == 'A' :\n",
    "            bp_map[i][CONST_A] += magnitude\n",
    "        elif seq[i] == 'C' :\n",
    "            bp_map[i][CONST_C] += magnitude\n",
    "        elif seq[i] == 'G' :\n",
    "            bp_map[i][CONST_G] += magnitude\n",
    "        elif seq[i] == 'T' :\n",
    "            bp_map[i][CONST_T] += magnitude\n",
    "    return bp_map\n",
    "\n",
    "def get_consensus_sequence(bp_map) :\n",
    "    seq = ''\n",
    "    for i in range(0, len(bp_map)) :\n",
    "        max_count = 0\n",
    "        max_j = 0\n",
    "        for j in range(0, 4) :\n",
    "            if bp_map[i][j] > max_count :\n",
    "                max_count = bp_map[i][j]\n",
    "                max_j = j\n",
    "        seq += CONST_NT_MAP[max_j]\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 'r1_dna.fq'\n",
    "r2 = 'r2_dna.fq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_one = re.compile(r\"(CATTACTCGCATCCA){s<=2}\")#s<=1\n",
    "tag_two = re.compile(r\"(CAGCCAATTAAGCC){s<=2}\")#s<=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Num dna reads passed: 0\n",
      "Num dna reads failed: 1\n",
      "1000000\n",
      "Num dna reads passed: 644591\n",
      "Num dna reads failed: 355410\n",
      "2000000\n",
      "Num dna reads passed: 1302884\n",
      "Num dna reads failed: 697117\n",
      "3000000\n",
      "Num dna reads passed: 1950318\n",
      "Num dna reads failed: 1049683\n",
      "4000000\n",
      "Num dna reads passed: 2575455\n",
      "Num dna reads failed: 1424546\n",
      "5000000\n",
      "Num dna reads passed: 3184032\n",
      "Num dna reads failed: 1815969\n",
      "6000000\n",
      "Num dna reads passed: 3826062\n",
      "Num dna reads failed: 2173939\n",
      "7000000\n",
      "Num dna reads passed: 4473896\n",
      "Num dna reads failed: 2526105\n",
      "8000000\n",
      "Num dna reads passed: 5099515\n",
      "Num dna reads failed: 2900486\n",
      "9000000\n",
      "Num dna reads passed: 5729395\n",
      "Num dna reads failed: 3270606\n",
      "10000000\n",
      "Num dna reads passed: 6367827\n",
      "Num dna reads failed: 3632174\n",
      "11000000\n",
      "Num dna reads passed: 7014495\n",
      "Num dna reads failed: 3985506\n",
      "12000000\n",
      "Num dna reads passed: 7656587\n",
      "Num dna reads failed: 4343414\n",
      "13000000\n",
      "Num dna reads passed: 8296389\n",
      "Num dna reads failed: 4703612\n",
      "14000000\n",
      "Num dna reads passed: 8933237\n",
      "Num dna reads failed: 5066764\n",
      "15000000\n",
      "Num dna reads passed: 9598779\n",
      "Num dna reads failed: 5401222\n",
      "16000000\n",
      "Num dna reads passed: 10233535\n",
      "Num dna reads failed: 5766466\n",
      "17000000\n",
      "Num dna reads passed: 10832177\n",
      "Num dna reads failed: 6167824\n",
      "18000000\n",
      "Num dna reads passed: 11417584\n",
      "Num dna reads failed: 6582417\n",
      "19000000\n",
      "Num dna reads passed: 11984870\n",
      "Num dna reads failed: 7015131\n",
      "20000000\n",
      "Num dna reads passed: 12526849\n",
      "Num dna reads failed: 7473152\n",
      "21000000\n",
      "Num dna reads passed: 13096163\n",
      "Num dna reads failed: 7903838\n",
      "22000000\n",
      "Num dna reads passed: 13651124\n",
      "Num dna reads failed: 8348877\n",
      "23000000\n",
      "Num dna reads passed: 14179979\n",
      "Num dna reads failed: 8820022\n",
      "24000000\n",
      "Num dna reads passed: 14729998\n",
      "Num dna reads failed: 9270003\n",
      "25000000\n",
      "Num dna reads passed: 15273373\n",
      "Num dna reads failed: 9726628\n",
      "26000000\n",
      "Num dna reads passed: 15824335\n",
      "Num dna reads failed: 10175666\n",
      "27000000\n",
      "Num dna reads passed: 16399056\n",
      "Num dna reads failed: 10600945\n",
      "28000000\n",
      "Num dna reads passed: 16991917\n",
      "Num dna reads failed: 11008084\n",
      "29000000\n",
      "Num dna reads passed: 17575710\n",
      "Num dna reads failed: 11424291\n",
      "COMPLETE\n",
      "Num dna reads passed: 18036928\n",
      "Num dna reads failed: 11708032\n"
     ]
    }
   ],
   "source": [
    "f = {}\n",
    "f[0] = open(r1,'r')\n",
    "f[1] = open(r2,'r')\n",
    "\n",
    "head, seq, pr, q = ({} for i in range(4))\n",
    "count = 0\n",
    "\n",
    "n_passed = 0\n",
    "n_failed = 0\n",
    "\n",
    "f_out = open('dna_doubledope_raw_barcode_reads.csv', 'w')\n",
    "\n",
    "barcode_sequence_count_dict = {}\n",
    "\n",
    "while True:\n",
    "    for i in range(2):\n",
    "        head[i] = f[i].readline().rstrip()\n",
    "        seq[i] = f[i].readline().rstrip()\n",
    "        pr[i] = f[i].readline().rstrip()\n",
    "        q[i] = f[i].readline().rstrip()\n",
    "    if len(seq[0]) == 0:\n",
    "        break # End of File\n",
    "    \n",
    "    scan_one_r1   = re.search(tag_one, seq[0][20:35])\n",
    "    scan_two_r1   = re.search(tag_two, seq[0][106:120])\n",
    "    #scan_one_r2rc = re.search(tag_one, rc_seq[29:44])\n",
    "    #scan_two_r2rc = re.search(tag_two, rc_seq[115:129])\n",
    "    \n",
    "    rc_seq = reverse_complement(seq[1])\n",
    "    if scan_one_r1 is not None and scan_two_r1 is not None and distance(seq[0][:191], rc_seq[9:200]) <= 2 :#<=1\n",
    "        sequence = seq[0][20:191]\n",
    "        barcode = seq[0][:20]\n",
    "        \n",
    "        f_out.write(barcode + ',' + str(n_passed) + '\\n')\n",
    "        \n",
    "        if barcode not in barcode_sequence_count_dict :\n",
    "            barcode_sequence_count_dict[barcode] = {}\n",
    "        \n",
    "        if sequence not in barcode_sequence_count_dict[barcode] :\n",
    "            barcode_sequence_count_dict[barcode][sequence] = 0\n",
    "        \n",
    "        barcode_sequence_count_dict[barcode][sequence] += 1\n",
    "        \n",
    "        n_passed += 1\n",
    "    else :\n",
    "        n_failed += 1\n",
    "            \n",
    "    if (count % 1000000) == 0 :\n",
    "        print(count)\n",
    "        print('Num dna reads passed: ' + str(n_passed))\n",
    "        print('Num dna reads failed: ' + str(n_failed))\n",
    "    count += 1\n",
    "\n",
    "print('COMPLETE')\n",
    "print('Num dna reads passed: ' + str(n_passed))\n",
    "print('Num dna reads failed: ' + str(n_failed))\n",
    "\n",
    "pickle.dump(barcode_sequence_count_dict, open('barcode_sequence_count_dict.pickle', 'wb'))\n",
    "\n",
    "f[0].close()\n",
    "f[1].close()\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#barcode_sequence_count_dict = pickle.load(open('barcode_sequence_count_dict.pickle', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bartender command\n",
    "#bartender_single_com -f dna_doubledope_raw_barcode_reads.csv -o doubledope_hamming2 -c 2 -d 2 -z 5 -t 4\n",
    "#2551978 unique barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2551978\n",
      "2782080\n"
     ]
    }
   ],
   "source": [
    "#Read and map Bartender clustered barcodes, accumulate consensus sequences\n",
    "\n",
    "bartender_prefix = 'doubledope_hamming2'\n",
    "\n",
    "cluster_dict = pd.read_csv(bartender_prefix + '_cluster.csv', delimiter=',').set_index('Cluster.ID').to_dict(orient='index')\n",
    "print(len(cluster_dict))\n",
    "\n",
    "barcode_dict = pd.read_csv(bartender_prefix + '_barcode.csv', delimiter=',').set_index('Unique.reads').to_dict(orient='index')\n",
    "print(len(barcode_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2551978\n",
      "2782080\n",
      "Processing barcode 0\n",
      "Processing barcode 500000\n",
      "Processing barcode 1000000\n",
      "Processing barcode 1500000\n",
      "Processing barcode 2000000\n",
      "Processing barcode 2500000\n"
     ]
    }
   ],
   "source": [
    "cluster_sequence_count_dict = {}\n",
    "\n",
    "i = 0\n",
    "for raw_barcode in barcode_dict :\n",
    "    if i % 500000 == 0 :\n",
    "        print('Processing barcode ' + str(i))\n",
    "    \n",
    "    cluster_id = barcode_dict[raw_barcode]['Cluster.ID']\n",
    "    cluster = cluster_dict[cluster_id]\n",
    "    clustered_barcode = cluster['Center']\n",
    "    \n",
    "    raw_sequence_dict = barcode_sequence_count_dict[raw_barcode]\n",
    "    \n",
    "    if clustered_barcode not in cluster_sequence_count_dict :\n",
    "        cluster_sequence_count_dict[clustered_barcode] = {}\n",
    "    \n",
    "    for raw_sequence in raw_sequence_dict :\n",
    "        if raw_sequence not in cluster_sequence_count_dict[clustered_barcode] :\n",
    "            cluster_sequence_count_dict[clustered_barcode][raw_sequence] = 0\n",
    "        \n",
    "        cluster_sequence_count_dict[clustered_barcode][raw_sequence] += raw_sequence_dict[raw_sequence]\n",
    "\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cluster_sequence_count_dict, open('cluster_sequence_count_dict.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_sequence_count_dict = None\n",
    "cluster_dict = None\n",
    "barcode_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing barcode 0\n",
      "Processing barcode 500000\n",
      "Processing barcode 1000000\n",
      "Processing barcode 1500000\n",
      "Processing barcode 2000000\n",
      "Processing barcode 2500000\n",
      "165200\n"
     ]
    }
   ],
   "source": [
    "#Basepair vote consensus sequences\n",
    "\n",
    "seq_dict = {}\n",
    "count_dict = {}\n",
    "\n",
    "i = 0\n",
    "for barcode in cluster_sequence_count_dict :\n",
    "    if i % 500000 == 0 :\n",
    "        print('Processing barcode ' + str(i))\n",
    "    \n",
    "    sequence_count_dict = cluster_sequence_count_dict[barcode]\n",
    "    \n",
    "    bp_map = np.zeros((171, 4))\n",
    "    \n",
    "    total_count = 0\n",
    "    \n",
    "    for sequence in sequence_count_dict :\n",
    "        sequence_count = sequence_count_dict[sequence]\n",
    "        for j in range(0, len(sequence)) :\n",
    "            if sequence[j] == 'A' :\n",
    "                bp_map[j, 0] += sequence_count\n",
    "            elif sequence[j] == 'C' :\n",
    "                bp_map[j, 1] += sequence_count\n",
    "            elif sequence[j] == 'G' :\n",
    "                bp_map[j, 2] += sequence_count\n",
    "            elif sequence[j] == 'T' :\n",
    "                bp_map[j, 3] += sequence_count\n",
    "        \n",
    "        total_count += sequence_count\n",
    "    \n",
    "    consensus_sequence = ''\n",
    "    for j in range(0, 171) :\n",
    "        max_i = int(np.argmax(bp_map[j, :]))\n",
    "        \n",
    "        if max_i == 0 :\n",
    "            consensus_sequence += 'A'\n",
    "        elif max_i == 1 :\n",
    "            consensus_sequence += 'C'\n",
    "        elif max_i == 2 :\n",
    "            consensus_sequence += 'G'\n",
    "        elif max_i == 3 :\n",
    "            consensus_sequence += 'T'\n",
    "    \n",
    "    seq_dict[barcode] = consensus_sequence\n",
    "    count_dict[barcode] = total_count\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2551978\n"
     ]
    }
   ],
   "source": [
    "print(len(seq_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2551978\n"
     ]
    }
   ],
   "source": [
    "dna_barcode_list = []\n",
    "dna_seq_list = []\n",
    "dna_count_list = []\n",
    "\n",
    "for barcode in seq_dict :\n",
    "    dna_barcode_list.append(barcode)\n",
    "    dna_seq_list.append(seq_dict[barcode])\n",
    "    dna_count_list.append(count_dict[barcode])\n",
    "\n",
    "df = pd.DataFrame({'barcode':    dna_barcode_list,\n",
    "                   'sequence':   dna_seq_list,\n",
    "                   'read_count': dna_count_list})\n",
    "\n",
    "df = df.sort_values(by='read_count', ascending=False)\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "new_columns = ['barcode', 'sequence', 'read_count']\n",
    "\n",
    "df.to_csv('doubledope_dna_hamming2.csv', sep=',', header=True, columns=new_columns, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
