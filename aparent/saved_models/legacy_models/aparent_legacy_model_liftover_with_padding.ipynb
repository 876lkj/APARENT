{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, LSTM, ConvLSTM2D, BatchNormalization\n",
    "from keras.layers import Concatenate, Reshape\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import keras.losses\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load isoform legacy model (theano weight files)\n",
    "legacy_model_name = 'generalapa_sparse_general_global_onesided2antimisprimeorigdropout_finetuned_TOMM5_APA_Six_30_31_34_default'\n",
    "\n",
    "legacy_iso_conv_layer_1_w = np.load(legacy_model_name + '_conv0_left_w.npy')\n",
    "legacy_iso_conv_layer_1_b = np.load(legacy_model_name + '_conv0_left_b.npy')\n",
    "\n",
    "legacy_iso_conv_layer_2_w = np.load(legacy_model_name + '_conv1_w.npy')\n",
    "legacy_iso_conv_layer_2_b = np.load(legacy_model_name + '_conv1_b.npy')\n",
    "\n",
    "legacy_iso_dense_layer_1_w = np.load(legacy_model_name + '_mlp_w.npy')\n",
    "legacy_iso_dense_layer_1_b = np.load(legacy_model_name + '_mlp_b.npy')\n",
    "\n",
    "legacy_iso_out_layer_w = np.load(legacy_model_name + '_lr_w.npy')\n",
    "legacy_iso_out_layer_b = np.load(legacy_model_name + '_lr_b.npy')\n",
    "\n",
    "#Load cut legacy model (theano weight files)\n",
    "legacy_cut_model_name = 'generalapa_sparse_general_global_onesided2cuts2antimisprimeorigdropout_finetuned_TOMM5_APA_Six_30_31_34_default'#_pasaligned\n",
    "\n",
    "legacy_cut_conv_layer_1_w = np.load(legacy_cut_model_name + '_conv0_left_w.npy')\n",
    "legacy_cut_conv_layer_1_b = np.load(legacy_cut_model_name + '_conv0_left_b.npy')\n",
    "\n",
    "legacy_cut_conv_layer_2_w = np.load(legacy_cut_model_name + '_conv1_w.npy')\n",
    "legacy_cut_conv_layer_2_b = np.load(legacy_cut_model_name + '_conv1_b.npy')\n",
    "\n",
    "legacy_cut_dense_layer_1_w = np.load(legacy_cut_model_name + '_mlp_w.npy')\n",
    "legacy_cut_dense_layer_1_b = np.load(legacy_cut_model_name + '_mlp_b.npy')\n",
    "\n",
    "legacy_cut_out_layer_w = np.load(legacy_cut_model_name + '_lr_w.npy')\n",
    "legacy_cut_out_layer_b = np.load(legacy_cut_model_name + '_lr_b.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_libraries = [2, 5, 8, 11, 20, 22, 31, 32, 33, 34, 35, 40, 30]\n",
    "\n",
    "embedding_w = np.zeros((13, 36))\n",
    "for i, lib in enumerate(unique_libraries) :\n",
    "    if lib < embedding_w.shape[1] :\n",
    "        embedding_w[i, lib] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APARENT parameters\n",
    "seq_input_shape = (205, 4, 1)\n",
    "lib_input_shape = (13,)\n",
    "distal_pas_shape = (1,)\n",
    "\n",
    "\n",
    "#Isoform model definition\n",
    "iso_layer_1 = Conv2D(70, (8, 4), padding='valid', activation='relu', kernel_initializer='zeros', data_format='channels_first', name='iso_conv_layer_1')\n",
    "iso_layer_1_pool = MaxPooling2D(pool_size=(2, 1), data_format='channels_first', name='iso_maxpool_layer_1')\n",
    "iso_layer_2 = Conv2D(110, (6, 1), padding='valid', activation='relu', kernel_initializer='zeros', data_format='channels_first', name='iso_conv_layer_2')\n",
    "iso_layer_dense = Dense(80, activation='relu', kernel_initializer='zeros', name='iso_dense_layer_1')\n",
    "iso_layer_drop = Dropout(0.2, name='iso_drop_layer_1')\n",
    "iso_layer_out = Dense(2, activation='softmax', kernel_initializer='zeros', name='iso_out_layer_1')\n",
    "\n",
    "def iso_model(seq_input, distal_pas_input, lib_input) :\n",
    "    return iso_layer_out(\n",
    "        Concatenate()([\n",
    "            iso_layer_drop(\n",
    "                iso_layer_dense(\n",
    "                    Concatenate()([\n",
    "                        Flatten()(\n",
    "                            iso_layer_2(\n",
    "                                iso_layer_1_pool(\n",
    "                                    iso_layer_1(\n",
    "                                        seq_input\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "                        ),\n",
    "                        distal_pas_input\n",
    "                    ])\n",
    "                )\n",
    "            ),\n",
    "            lib_input\n",
    "        ])\n",
    "    )\n",
    "\n",
    "#Cut model definition\n",
    "cut_layer_1 = Conv2D(70, (8, 4), padding='valid', activation='relu', kernel_initializer='zeros', data_format='channels_first', name='cut_conv_layer_1')\n",
    "cut_layer_1_pool = MaxPooling2D(pool_size=(2, 1), data_format='channels_first', name='cut_maxpool_layer_1')\n",
    "cut_layer_2 = Conv2D(110, (6, 1), padding='valid', activation='relu', kernel_initializer='zeros', data_format='channels_first', name='cut_conv_layer_2')\n",
    "cut_layer_dense = Dense(400, activation='relu', kernel_initializer='zeros', name='cut_dense_layer_1')\n",
    "cut_layer_drop = Dropout(0.2, name='cut_drop_layer_1')\n",
    "cut_layer_out = Dense(186, activation='softmax', kernel_initializer='zeros', name='cut_out_layer_1')\n",
    "\n",
    "def cut_model(seq_input, distal_pas_input, lib_input) :\n",
    "    return cut_layer_out(\n",
    "        Concatenate()([\n",
    "            cut_layer_drop(\n",
    "                cut_layer_dense(\n",
    "                    Concatenate()([\n",
    "                        Flatten()(\n",
    "                            cut_layer_2(\n",
    "                                cut_layer_1_pool(\n",
    "                                    cut_layer_1(\n",
    "                                        seq_input\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "                        ),\n",
    "                        distal_pas_input\n",
    "                    ])\n",
    "                )\n",
    "            ),\n",
    "            lib_input\n",
    "        ])\n",
    "    )\n",
    "\n",
    "\n",
    "#Join model definition\n",
    "\n",
    "#Inputs\n",
    "seq_input = Input(shape=seq_input_shape)\n",
    "lib_input = Input(shape=lib_input_shape)\n",
    "distal_pas_input = Input(shape=distal_pas_shape)\n",
    "\n",
    "seq_input_flipped = Lambda(lambda x: K.permute_dimensions(x, (0, 3, 1, 2)), output_shape=(1, 205, 4))(seq_input)\n",
    "\n",
    "layer_lib_embedding = Dense(36, use_bias=False, name='lib_embedding')\n",
    "embed_lib_input = layer_lib_embedding(lib_input)\n",
    "\n",
    "layer_trim_up = Lambda(lambda x: K.concatenate([x[:, :, 21:, :], K.tile(K.variable(np.zeros((1, 1, 1, 4))), (K.shape(x)[0], 1, 1, 1))], axis=2) , output_shape=(1, 185, 4))\n",
    "trimmed_seq_input = layer_trim_up(seq_input_flipped)\n",
    "\n",
    "out_iso = iso_model(trimmed_seq_input, distal_pas_input, embed_lib_input)\n",
    "out_cut = cut_model(trimmed_seq_input, distal_pas_input, embed_lib_input)\n",
    "\n",
    "out_iso_trimmed = Lambda(lambda x: K.expand_dims(x[:, 1], axis=-1), output_shape=(1,))(out_iso)\n",
    "\n",
    "layer_trim_dn = Lambda(lambda x: K.concatenate([x[:, :184], K.expand_dims(x[:, 185], axis=-1)], axis=1), output_shape=(185,))\n",
    "layer_pad_up = Lambda(lambda x: K.concatenate([K.tile(K.variable(np.zeros((1, 21))), (K.shape(x)[0], 1)), x], axis=1), output_shape=(206,))\n",
    "\n",
    "out_cut_padded = layer_pad_up(layer_trim_dn(out_cut))\n",
    "\n",
    "plasmid_model = Model(\n",
    "    inputs=[\n",
    "        seq_input,\n",
    "        lib_input,\n",
    "        distal_pas_input\n",
    "    ],\n",
    "    outputs=[\n",
    "        out_iso_trimmed,\n",
    "        out_cut_padded\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer legacy theano weights to the new keras model\n",
    "\n",
    "#Transfer isoform model weights\n",
    "legacy_iso_conv_layer_1_w_flipped = legacy_iso_conv_layer_1_w[:, :, ::-1, ::-1]\n",
    "legacy_iso_conv_layer_2_w_flipped = legacy_iso_conv_layer_2_w[:, :, ::-1, ::-1]\n",
    "legacy_iso_conv_layer_1_w_permuted = np.moveaxis(np.moveaxis(legacy_iso_conv_layer_1_w_flipped, 0, -1), 0, 2)\n",
    "legacy_iso_conv_layer_2_w_permuted = np.moveaxis(np.moveaxis(legacy_iso_conv_layer_2_w_flipped, 0, -1), 0, 2)\n",
    "\n",
    "iso_layer_1.set_weights([legacy_iso_conv_layer_1_w_permuted, legacy_iso_conv_layer_1_b])\n",
    "iso_layer_2.set_weights([legacy_iso_conv_layer_2_w_permuted, legacy_iso_conv_layer_2_b])\n",
    "iso_layer_dense.set_weights([legacy_iso_dense_layer_1_w, legacy_iso_dense_layer_1_b])\n",
    "iso_layer_out.set_weights([legacy_iso_out_layer_w, legacy_iso_out_layer_b])\n",
    "\n",
    "#Transfer cut model weights\n",
    "legacy_cut_conv_layer_1_w_flipped = legacy_cut_conv_layer_1_w[:, :, ::-1, ::-1]\n",
    "legacy_cut_conv_layer_2_w_flipped = legacy_cut_conv_layer_2_w[:, :, ::-1, ::-1]\n",
    "legacy_cut_conv_layer_1_w_permuted = np.moveaxis(np.moveaxis(legacy_cut_conv_layer_1_w_flipped, 0, -1), 0, 2)\n",
    "legacy_cut_conv_layer_2_w_permuted = np.moveaxis(np.moveaxis(legacy_cut_conv_layer_2_w_flipped, 0, -1), 0, 2)\n",
    "\n",
    "cut_layer_1.set_weights([legacy_cut_conv_layer_1_w_permuted, legacy_cut_conv_layer_1_b])\n",
    "cut_layer_2.set_weights([legacy_cut_conv_layer_2_w_permuted, legacy_cut_conv_layer_2_b])\n",
    "cut_layer_dense.set_weights([legacy_cut_dense_layer_1_w, legacy_cut_dense_layer_1_b])\n",
    "cut_layer_out.set_weights([legacy_cut_out_layer_w, legacy_cut_out_layer_b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at ./aparent_theano_legacy_30_31_34_padded.h5 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_dir = '.'\n",
    "new_legacy_model_name = 'aparent_theano_legacy_30_31_34_padded.h5'#'aparent_theano_legacy_30_31_34_pasaligned_padded.h5'\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_path = os.path.join(save_dir, new_legacy_model_name)\n",
    "plasmid_model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
